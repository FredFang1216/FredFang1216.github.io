<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="The roadmap was constructed on the following 4 principles.  From silhouette to details From the old one to new one From general techniques to specific domains Focus on state of the art techniques  1 T">
<meta property="og:type" content="article">
<meta property="og:title" content="The Deep Learning Papers reading roadmap">
<meta property="og:url" content="http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/index.html">
<meta property="og:site_name" content="FredFang&#39;s Blog">
<meta property="og:description" content="The roadmap was constructed on the following 4 principles.  From silhouette to details From the old one to new one From general techniques to specific domains Focus on state of the art techniques  1 T">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-02-12T08:54:08.405Z">
<meta property="article:modified_time" content="2023-02-13T08:27:54.578Z">
<meta property="article:author" content="Fred Fang">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>The Deep Learning Papers reading roadmap</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" aria-label="Next post" href="/2023/02/11/about/index/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&text=The Deep Learning Papers reading roadmap"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&is_video=false&description=The Deep Learning Papers reading roadmap"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=The Deep Learning Papers reading roadmap&body=Check out this article: http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&name=The Deep Learning Papers reading roadmap&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&t=The Deep Learning Papers reading roadmap"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-The-Basics-and-history-of-Deep-Learning"><span class="toc-number">1.</span> <span class="toc-text">1 The Basics and history of Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-0-Books"><span class="toc-number">1.1.</span> <span class="toc-text">1.0 Books</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-Reviews"><span class="toc-number">1.2.</span> <span class="toc-text">1.1 Reviews</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-Deep-Belief-Nets%EF%BC%88DBN"><span class="toc-number">1.3.</span> <span class="toc-text">1.2 Deep Belief Nets（DBN)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-ImageNet"><span class="toc-number">1.4.</span> <span class="toc-text">1.3 ImageNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-The-Development-of-Speech-Recognition"><span class="toc-number">1.5.</span> <span class="toc-text">1.4 The Development of Speech Recognition</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-The-methods-of-Deep-Learning"><span class="toc-number">2.</span> <span class="toc-text">2 The methods of Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Deep-Learning-Models"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 Deep Learning Models</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-Optimization-Methods"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 Optimization Methods</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-Unsupervised-Learning-Generative-Adversarial-Model"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 Unsupervised Learning&#x2F; Generative Adversarial Model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-RNN"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 RNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-Neural-Turing-Machines"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 Neural Turing Machines</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-Deep-Reinforcement-Learning"><span class="toc-number">2.6.</span> <span class="toc-text">2.6 Deep Reinforcement Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-7-Deep-Transfer-Learning-Lifelong-Machine-Learning"><span class="toc-number">2.7.</span> <span class="toc-text">2.7 Deep Transfer Learning&#x2F;Lifelong Machine Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-8-One-Shot-Deep-Learning"><span class="toc-number">2.8.</span> <span class="toc-text">2.8 One-Shot Deep Learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Applications"><span class="toc-number">3.</span> <span class="toc-text">3 Applications</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-NLP"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 NLP</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-Object-Detection"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 Object Detection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-Visual-Tracking"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 Visual Tracking</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-Image-Caption-Generator"><span class="toc-number">3.4.</span> <span class="toc-text">3.4 Image Caption Generator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-Neural-Machine-Translation"><span class="toc-number">3.5.</span> <span class="toc-text">3.5 Neural Machine Translation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-Robotics"><span class="toc-number">3.6.</span> <span class="toc-text">3.6 Robotics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-7-Art"><span class="toc-number">3.7.</span> <span class="toc-text">3.7 Art</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-8-Semantic-Segmentation"><span class="toc-number">3.8.</span> <span class="toc-text">3.8 Semantic Segmentation</span></a></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        The Deep Learning Papers reading roadmap
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">Fred Fang</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2023-02-12T08:54:08.405Z" class="dt-published" itemprop="datePublished">2023-02-12</time>
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>The roadmap was constructed on the following 4 principles.</p>
<ul>
<li>From silhouette to details</li>
<li>From the old one to new one</li>
<li>From general techniques to specific domains</li>
<li>Focus on state of the art techniques</li>
</ul>
<h3 id="1-The-Basics-and-history-of-Deep-Learning"><a href="#1-The-Basics-and-history-of-Deep-Learning" class="headerlink" title="1 The Basics and history of Deep Learning"></a>1 The Basics and history of Deep Learning</h3><h4 id="1-0-Books"><a href="#1-0-Books" class="headerlink" title="1.0 Books"></a>1.0 Books</h4><p>[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. “Deep learning.” An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) ⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="1-1-Reviews"><a href="#1-1-Reviews" class="headerlink" title="1.1 Reviews"></a>1.1 Reviews</h4><p>[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (Three Giants’ Survey) ⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="1-2-Deep-Belief-Nets（DBN"><a href="#1-2-Deep-Belief-Nets（DBN" class="headerlink" title="1.2 Deep Belief Nets（DBN)"></a>1.2 Deep Belief Nets（DBN)</h4><p>[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. “A fast learning algorithm for deep belief nets.” Neural computation 18.7 (2006): 1527-1554. <a href="Deep Learning Eve">pdf</a> ⭐️⭐️⭐️</p>
<p>[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “Reducing the dimensionality of data with neural networks.” Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) ⭐️⭐️⭐️</p>
<h4 id="1-3-ImageNet"><a href="#1-3-ImageNet" class="headerlink" title="1.3 ImageNet"></a>1.3 ImageNet</h4><p>[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “Imagenet classification with deep convolutional neural networks.” Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[5] Simonyan, Karen, and Andrew Zisserman. “Very deep convolutional networks for large-scale image recognition.” arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) ⭐️⭐️⭐️</p>
<p>[6] Szegedy, Christian, et al. “Going deeper with convolutions.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) ⭐️⭐️⭐️</p>
<p>[7] He, Kaiming, et al. “Deep residual learning for image recognition.” arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) ⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="1-4-The-Development-of-Speech-Recognition"><a href="#1-4-The-Development-of-Speech-Recognition" class="headerlink" title="1.4 The Development of Speech Recognition"></a>1.4 The Development of Speech Recognition</h4><p>[8] Hinton, Geoffrey, et al. “Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.” IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)⭐️⭐️⭐️⭐️</p>
<p>[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. “Speech recognition with deep recurrent neural networks.” 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)⭐️⭐️⭐️</p>
<p>[10] Graves, Alex, and Navdeep Jaitly. “Towards End-To-End Speech Recognition with Recurrent Neural Networks.” ICML. Vol. 14. 2014. [pdf]⭐️⭐️⭐️</p>
<p>[11] Sak, Haşim, et al. “Fast and accurate recurrent neural network acoustic models for speech recognition.” arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) ⭐️⭐️⭐️</p>
<p>[12] Amodei, Dario, et al. “Deep speech 2: End-to-end speech recognition in english and mandarin.” arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) ⭐️⭐️⭐️⭐️</p>
<p>[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig “Achieving Human Parity in Conversational Speech Recognition.” arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) ⭐️⭐️⭐️⭐️</p>
<h3 id="2-The-methods-of-Deep-Learning"><a href="#2-The-methods-of-Deep-Learning" class="headerlink" title="2 The methods of Deep Learning"></a>2 The methods of Deep Learning</h3><h4 id="2-1-Deep-Learning-Models"><a href="#2-1-Deep-Learning-Models" class="headerlink" title="2.1 Deep Learning Models"></a>2.1 Deep Learning Models</h4><p>[14] Hinton, Geoffrey E., et al. “Improving neural networks by preventing co-adaptation of feature detectors.” arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) ⭐️⭐️⭐️</p>
<p>[15] Srivastava, Nitish, et al. “Dropout: a simple way to prevent neural networks from overfitting.” Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] ⭐️⭐️⭐️</p>
<p>[16] Ioffe, Sergey, and Christian Szegedy. “Batch normalization: Accelerating deep network training by reducing internal covariate shift.” arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) ⭐️⭐️⭐️⭐️</p>
<p>[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. “Layer normalization.” arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) ⭐️⭐️⭐️⭐️</p>
<p>[18] Courbariaux, Matthieu, et al. “Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1.” [pdf] (New Model,Fast)  ⭐️⭐️⭐️</p>
<p>[19] Jaderberg, Max, et al. “Decoupled neural interfaces using synthetic gradients.” arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. “Net2net: Accelerating learning via knowledge transfer.” arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) ⭐️⭐️⭐️</p>
<p>[21] Wei, Tao, et al. “Network Morphism.” arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) ⭐️⭐️⭐️</p>
<h4 id="2-2-Optimization-Methods"><a href="#2-2-Optimization-Methods" class="headerlink" title="2.2 Optimization Methods"></a>2.2 Optimization Methods</h4><p>[22] Sutskever, Ilya, et al. “On the importance of initialization and momentum in deep learning.” ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) ⭐️⭐️</p>
<p>[23] Kingma, Diederik, and Jimmy Ba. “Adam: A method for stochastic optimization.” arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) ⭐️⭐️⭐️</p>
<p>[24] Andrychowicz, Marcin, et al. “Learning to learn by gradient descent by gradient descent.” arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[25] Han, Song, Huizi Mao, and William J. Dally. “Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.” CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[26] Iandola, Forrest N., et al. “SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&lt; 1MB model size.” arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) ⭐️⭐️⭐️⭐️</p>
<h4 id="2-3-Unsupervised-Learning-Generative-Adversarial-Model"><a href="#2-3-Unsupervised-Learning-Generative-Adversarial-Model" class="headerlink" title="2.3 Unsupervised Learning/ Generative Adversarial Model"></a>2.3 Unsupervised Learning/ Generative Adversarial Model</h4><p>[27] Le, Quoc V. “Building high-level features using large scale unsupervised learning.” 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) ⭐️⭐️⭐️⭐️</p>
<p>[28] Kingma, Diederik P., and Max Welling. “Auto-encoding variational bayes.” arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) ⭐️⭐️⭐️⭐️</p>
<p>[29] Goodfellow, Ian, et al. “Generative adversarial nets.” Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[30] Radford, Alec, Luke Metz, and Soumith Chintala. “Unsupervised representation learning with deep convolutional generative adversarial networks.” arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) ⭐️⭐️⭐️⭐️</p>
<p>[31] Gregor, Karol, et al. “DRAW: A recurrent neural network for image generation.” arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[32] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. “Pixel recurrent neural networks.” arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) ⭐️⭐️⭐️⭐️</p>
<p>[33] Oord, Aaron van den, et al. “Conditional image generation with PixelCNN decoders.” arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) ⭐️⭐️⭐️⭐️</p>
<h4 id="2-4-RNN"><a href="#2-4-RNN" class="headerlink" title="2.4 RNN"></a>2.4 RNN</h4><p>[34] Graves, Alex. “Generating sequences with recurrent neural networks.” arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) ⭐️⭐️⭐️⭐️</p>
<p>[35] Cho, Kyunghyun, et al. “Learning phrase representations using RNN encoder-decoder for statistical machine translation.” arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) ⭐️⭐️⭐️⭐️</p>
<p>[36] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. “Sequence to sequence learning with neural networks.” Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[37] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. “Neural Machine Translation by Jointly Learning to Align and Translate.” arXiv preprint arXiv:1409.0473 (2014). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[38] Vinyals, Oriol, and Quoc Le. “A neural conversational model.” arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) ⭐️⭐️⭐️</p>
<h4 id="2-5-Neural-Turing-Machines"><a href="#2-5-Neural-Turing-Machines" class="headerlink" title="2.5 Neural Turing Machines"></a>2.5 Neural Turing Machines</h4><p>[39] Graves, Alex, Greg Wayne, and Ivo Danihelka. “Neural turing machines.” arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[40] Zaremba, Wojciech, and Ilya Sutskever. “Reinforcement learning neural Turing machines.” arXiv preprint arXiv:1505.00521 362 (2015). [pdf] ⭐️⭐️⭐️</p>
<p>[41] Weston, Jason, Sumit Chopra, and Antoine Bordes. “Memory networks.” arXiv preprint arXiv:1410.3916 (2014). [pdf] ⭐️⭐️⭐️</p>
<p>[42] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. “End-to-end memory networks.” Advances in neural information processing systems. 2015. [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[43] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. “Pointer networks.” Advances in Neural Information Processing Systems. 2015. [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[44] Graves, Alex, et al. “Hybrid computing using a neural network with dynamic external memory.” Nature (2016). [pdf] (Milestone,combine above papers’ ideas) ⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="2-6-Deep-Reinforcement-Learning"><a href="#2-6-Deep-Reinforcement-Learning" class="headerlink" title="2.6 Deep Reinforcement Learning"></a>2.6 Deep Reinforcement Learning</h4><p>[45] Mnih, Volodymyr, et al. “Playing atari with deep reinforcement learning.” arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) ⭐️⭐️⭐️⭐️</p>
<p>[46] Mnih, Volodymyr, et al. “Human-level control through deep reinforcement learning.” Nature 518.7540 (2015): 529-533. [pdf] (Milestone) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[47] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. “Dueling network architectures for deep reinforcement learning.” arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  ⭐️⭐️⭐️⭐️</p>
<p>[48] Mnih, Volodymyr, et al. “Asynchronous methods for deep reinforcement learning.” arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[49] Lillicrap, Timothy P., et al. “Continuous control with deep reinforcement learning.” arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) ⭐️⭐️⭐️⭐️</p>
<p>[50] Gu, Shixiang, et al. “Continuous Deep Q-Learning with Model-based Acceleration.” arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) ⭐️⭐️⭐️⭐️</p>
<p>[51] Schulman, John, et al. “Trust region policy optimization.” CoRR, abs/1502.05477 (2015). [pdf] (TRPO) ⭐️⭐️⭐️⭐️</p>
<p>[52] Silver, David, et al. “Mastering the game of Go with deep neural networks and tree search.” Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) ⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="2-7-Deep-Transfer-Learning-Lifelong-Machine-Learning"><a href="#2-7-Deep-Transfer-Learning-Lifelong-Machine-Learning" class="headerlink" title="2.7 Deep Transfer Learning/Lifelong Machine Learning"></a>2.7 Deep Transfer Learning/Lifelong Machine Learning</h4><p>[53] Bengio, Yoshua. “Deep Learning of Representations for Unsupervised and Transfer Learning.” ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) ⭐️⭐️⭐️</p>
<p>[54] Silver, Daniel L., Qiang Yang, and Lianghao Li. “Lifelong Machine Learning Systems: Beyond Learning Algorithms.” AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  ⭐️⭐️⭐️</p>
<p>[55] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. “Distilling the knowledge in a neural network.” arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather’s Work) ⭐️⭐️⭐️⭐️</p>
<p>[56] Rusu, Andrei A., et al. “Policy distillation.” arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) ⭐️⭐️⭐️</p>
<p>[57] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. “Actor-mimic: Deep multitask and transfer reinforcement learning.” arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) ⭐️⭐️⭐️</p>
<p>[58] Rusu, Andrei A., et al. “Progressive neural networks.” arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) ⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="2-8-One-Shot-Deep-Learning"><a href="#2-8-One-Shot-Deep-Learning" class="headerlink" title="2.8 One-Shot Deep Learning"></a>2.8 One-Shot Deep Learning</h4><p>[59] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. “Human-level concept learning through probabilistic program induction.” Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[60] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. “Siamese Neural Networks for One-shot Image Recognition.”(2015) [pdf] ⭐️⭐️⭐️</p>
<p>[61] Santoro, Adam, et al. “One-shot Learning with Memory-Augmented Neural Networks.” arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) ⭐️⭐️⭐️⭐️</p>
<p>[62] Vinyals, Oriol, et al. “Matching Networks for One Shot Learning.” arXiv preprint arXiv:1606.04080 (2016). [pdf] ⭐️⭐️⭐️</p>
<p>[63] Hariharan, Bharath, and Ross Girshick. “Low-shot visual object recognition.” arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) ⭐️⭐️⭐️⭐️</p>
<h3 id="3-Applications"><a href="#3-Applications" class="headerlink" title="3 Applications"></a>3 Applications</h3><h4 id="3-1-NLP"><a href="#3-1-NLP" class="headerlink" title="3.1 NLP"></a>3.1 NLP</h4><p>[1] Antoine Bordes, et al. “Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.” AISTATS(2012) [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[2] Mikolov, et al. “Distributed representations of words and phrases and their compositionality.” ANIPS(2013): 3111-3119 [pdf] (word2vec) ⭐️⭐️⭐️</p>
<p>[3] Sutskever, et al. ““Sequence to sequence learning with neural networks.” ANIPS(2014) [pdf] ⭐️⭐️⭐️</p>
<p>[4] Ankit Kumar, et al. ““Ask Me Anything: Dynamic Memory Networks for Natural Language Processing.” arXiv preprint arXiv:1506.07285(2015) [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[5] Yoon Kim, et al. “Character-Aware Neural Language Models.” NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[6] Jason Weston, et al. “Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.” arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) ⭐️⭐️⭐️</p>
<p>[7] Karl Moritz Hermann, et al. “Teaching Machines to Read and Comprehend.” arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) ⭐️⭐️</p>
<p>[8] Alexis Conneau, et al. “Very Deep Convolutional Networks for Natural Language Processing.” arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) ⭐️⭐️⭐️</p>
<p>[9] Armand Joulin, et al. “Bag of Tricks for Efficient Text Classification.” arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) ⭐️⭐️⭐️</p>
<h4 id="3-2-Object-Detection"><a href="#3-2-Object-Detection" class="headerlink" title="3.2 Object Detection"></a>3.2 Object Detection</h4><p>[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. “Deep neural networks for object detection.” Advances in Neural Information Processing Systems. 2013. [pdf] ⭐️⭐️⭐️</p>
<p>[2] Girshick, Ross, et al. “Rich feature hierarchies for accurate object detection and semantic segmentation.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[3] He, Kaiming, et al. “Spatial pyramid pooling in deep convolutional networks for visual recognition.” European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) ⭐️⭐️⭐️⭐️</p>
<p>[4] Girshick, Ross. “Fast r-cnn.” Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[5] Ren, Shaoqing, et al. “Faster R-CNN: Towards real-time object detection with region proposal networks.” Advances in neural information processing systems. 2015. [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[6] Redmon, Joseph, et al. “You only look once: Unified, real-time object detection.” arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[7] Liu, Wei, et al. “SSD: Single Shot MultiBox Detector.” arXiv preprint arXiv:1512.02325 (2015). [pdf] ⭐️⭐️⭐️</p>
<p>[8] Dai, Jifeng, et al. “R-FCN: Object Detection via<br>Region-based Fully Convolutional Networks.” arXiv preprint arXiv:1605.06409 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[9] He, Gkioxari, et al. “Mask R-CNN” arXiv preprint arXiv:1703.06870 (2017). [pdf] ⭐️⭐️⭐️⭐️</p>
<h4 id="3-3-Visual-Tracking"><a href="#3-3-Visual-Tracking" class="headerlink" title="3.3 Visual Tracking"></a>3.3 Visual Tracking</h4><p>[1] Wang, Naiyan, and Dit-Yan Yeung. “Learning a deep compact image representation for visual tracking.” Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) ⭐️⭐️⭐️</p>
<p>[2] Wang, Naiyan, et al. “Transferring rich feature hierarchies for robust visual tracking.” arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) ⭐️⭐️⭐️⭐️</p>
<p>[3] Wang, Lijun, et al. “Visual tracking with fully convolutional networks.” Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) ⭐️⭐️⭐️⭐️</p>
<p>[4] Held, David, Sebastian Thrun, and Silvio Savarese. “Learning to Track at 100 FPS with Deep Regression Networks.” arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) ⭐️⭐️⭐️⭐️</p>
<p>[5] Bertinetto, Luca, et al. “Fully-Convolutional Siamese Networks for Object Tracking.” arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) ⭐️⭐️⭐️⭐️</p>
<p>[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. “Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.” ECCV (2016) [pdf] (C-COT) ⭐️⭐️⭐️⭐️</p>
<p>[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. “Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.” arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) ⭐️⭐️⭐️⭐️</p>
<h4 id="3-4-Image-Caption-Generator"><a href="#3-4-Image-Caption-Generator" class="headerlink" title="3.4 Image Caption Generator"></a>3.4 Image Caption Generator</h4><p>[1] Farhadi,Ali,etal. “Every picture tells a story: Generating sentences from images”. In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] ⭐️⭐️⭐️</p>
<p>[2] Kulkarni, Girish, et al. “Baby talk: Understanding and generating image descriptions”. In Proceedings of the 24th CVPR, 2011. [pdf]⭐️⭐️⭐️⭐️</p>
<p>[3] Vinyals, Oriol, et al. “Show and tell: A neural image caption generator”. In arXiv preprint arXiv:1411.4555, 2014. [pdf]⭐️⭐️⭐️</p>
<p>[4] Donahue, Jeff, et al. “Long-term recurrent convolutional networks for visual recognition and description”. In arXiv preprint arXiv:1411.4389 ,2014. [pdf]</p>
<p>[5] Karpathy, Andrej, and Li Fei-Fei. “Deep visual-semantic alignments for generating image descriptions”. In arXiv preprint arXiv:1412.2306, 2014. [pdf]⭐️⭐️⭐️⭐️⭐️</p>
<p>[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. “Deep fragment embeddings for bidirectional image sentence mapping”. In Advances in neural information processing systems, 2014. [pdf]⭐️⭐️⭐️⭐️</p>
<p>[7] Fang, Hao, et al. “From captions to visual concepts and back”. In arXiv preprint arXiv:1411.4952, 2014. [pdf]⭐️⭐️⭐️⭐️⭐️</p>
<p>[8] Chen, Xinlei, and C. Lawrence Zitnick. “Learning a recurrent visual representation for image caption generation”. In arXiv preprint arXiv:1411.5654, 2014. [pdf]⭐️⭐️⭐️⭐️</p>
<p>[9] Mao, Junhua, et al. “Deep captioning with multimodal recurrent neural networks (m-rnn)”. In arXiv preprint arXiv:1412.6632, 2014. [pdf]⭐️⭐️⭐️</p>
<p>[10] Xu, Kelvin, et al. “Show, attend and tell: Neural image caption generation with visual attention”. In arXiv preprint arXiv:1502.03044, 2015. [pdf]⭐️⭐️⭐️⭐️⭐️</p>
<h4 id="3-5-Neural-Machine-Translation"><a href="#3-5-Neural-Machine-Translation" class="headerlink" title="3.5 Neural Machine Translation"></a>3.5 Neural Machine Translation</h4><p>Some milestone papers are listed in RNN / Seq-to-Seq topic.</p>
<p>[1] Luong, Minh-Thang, et al. “Addressing the rare word problem in neural machine translation.” arXiv preprint arXiv:1410.8206 (2014). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[2] Sennrich, et al. “Neural Machine Translation of Rare Words with Subword Units”. In arXiv preprint arXiv:1508.07909, 2015. [pdf]⭐️⭐️⭐️</p>
<p>[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. “Effective approaches to attention-based neural machine translation.” arXiv preprint arXiv:1508.04025 (2015). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[4] Chung, et al. “A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation”. In arXiv preprint arXiv:1603.06147, 2016. [pdf]⭐️⭐️</p>
<p>[5] Lee, et al. “Fully Character-Level Neural Machine Translation without Explicit Segmentation”. In arXiv preprint arXiv:1610.03017, 2016. [pdf]⭐️⭐️⭐️⭐️⭐️</p>
<p>[6] Wu, Schuster, Chen, Le, et al. “Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation”. In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) ⭐️⭐️⭐️⭐️</p>
<h4 id="3-6-Robotics"><a href="#3-6-Robotics" class="headerlink" title="3.6 Robotics"></a>3.6 Robotics</h4><p>[1] Koutník, Jan, et al. “Evolving large-scale neural networks for vision-based reinforcement learning.” Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] ⭐️⭐️⭐️</p>
<p>[2] Levine, Sergey, et al. “End-to-end training of deep visuomotor policies.” Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] ⭐️⭐️⭐️⭐️⭐️</p>
<p>[3] Pinto, Lerrel, and Abhinav Gupta. “Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.” arXiv preprint arXiv:1509.06825 (2015). [pdf] ⭐️⭐️⭐️</p>
<p>[4] Levine, Sergey, et al. “Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.” arXiv preprint arXiv:1603.02199 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[5] Zhu, Yuke, et al. “Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.” arXiv preprint arXiv:1609.05143 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[6] Yahya, Ali, et al. “Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.” arXiv preprint arXiv:1610.00673 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[7] Gu, Shixiang, et al. “Deep Reinforcement Learning for Robotic Manipulation.” arXiv preprint arXiv:1610.00633 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[8] A Rusu, M Vecerik, Thomas Rothörl, N Heess, R Pascanu, R Hadsell.”Sim-to-Real Robot Learning from Pixels with Progressive Nets.” arXiv preprint arXiv:1610.04286 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[9] Mirowski, Piotr, et al. “Learning to navigate in complex environments.” arXiv preprint arXiv:1611.03673 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<h4 id="3-7-Art"><a href="#3-7-Art" class="headerlink" title="3.7 Art"></a>3.7 Art</h4><p>[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). “Inceptionism: Going Deeper into Neural Networks”. Google Research. [html] (Deep Dream)<br>⭐️⭐️⭐️⭐️</p>
<p>[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. “A neural algorithm of artistic style.” arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) ⭐️⭐️⭐️⭐️⭐️</p>
<p>[3] Zhu, Jun-Yan, et al. “Generative Visual Manipulation on the Natural Image Manifold.” European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) ⭐️⭐️⭐️⭐️</p>
<p>[4] Champandard, Alex J. “Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.” arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) ⭐️⭐️⭐️⭐️</p>
<p>[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. “Colorful Image Colorization.” arXiv preprint arXiv:1603.08511 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. “Perceptual losses for real-time style transfer and super-resolution.” arXiv preprint arXiv:1603.08155 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. “A learned representation for artistic style.” arXiv preprint arXiv:1610.07629 (2016). [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[8] Gatys, Leon and Ecker, et al.”Controlling Perceptual Factors in Neural Style Transfer.” arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)⭐️⭐️⭐️⭐️</p>
<p>[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. “Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.” arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) ⭐️⭐️⭐️⭐️</p>
<h4 id="3-8-Semantic-Segmentation"><a href="#3-8-Semantic-Segmentation" class="headerlink" title="3.8 Semantic Segmentation"></a>3.8 Semantic Segmentation</h4><p>[1] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation.” in CVPR, 2015. [pdf] ⭐️⭐️⭐️⭐️⭐️</p>
<p>[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. “Semantic image segmentation with deep convolutional nets and fully connected crfs.” In ICLR, 2015. [pdf] ⭐️⭐️⭐️⭐️⭐️</p>
<p>[3] Pinheiro, P.O., Collobert, R., Dollar, P. “Learning to segment object candidates.” In: NIPS. 2015. [pdf] ⭐️⭐️⭐️⭐️</p>
<p>[4] Dai, J., He, K., Sun, J. “Instance-aware semantic segmentation via multi-task network cascades.” in CVPR. 2016 [pdf] ⭐️⭐️⭐️</p>
<p>[5] Dai, J., He, K., Sun, J. “Instance-sensitive Fully Convolutional Networks.” arXiv preprint arXiv:1603.08678 (2016). [pdf] ⭐️⭐️⭐️</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-The-Basics-and-history-of-Deep-Learning"><span class="toc-number">1.</span> <span class="toc-text">1 The Basics and history of Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-0-Books"><span class="toc-number">1.1.</span> <span class="toc-text">1.0 Books</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-Reviews"><span class="toc-number">1.2.</span> <span class="toc-text">1.1 Reviews</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-Deep-Belief-Nets%EF%BC%88DBN"><span class="toc-number">1.3.</span> <span class="toc-text">1.2 Deep Belief Nets（DBN)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-ImageNet"><span class="toc-number">1.4.</span> <span class="toc-text">1.3 ImageNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-The-Development-of-Speech-Recognition"><span class="toc-number">1.5.</span> <span class="toc-text">1.4 The Development of Speech Recognition</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-The-methods-of-Deep-Learning"><span class="toc-number">2.</span> <span class="toc-text">2 The methods of Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Deep-Learning-Models"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 Deep Learning Models</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-Optimization-Methods"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 Optimization Methods</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-Unsupervised-Learning-Generative-Adversarial-Model"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 Unsupervised Learning&#x2F; Generative Adversarial Model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-RNN"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 RNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-Neural-Turing-Machines"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 Neural Turing Machines</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-Deep-Reinforcement-Learning"><span class="toc-number">2.6.</span> <span class="toc-text">2.6 Deep Reinforcement Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-7-Deep-Transfer-Learning-Lifelong-Machine-Learning"><span class="toc-number">2.7.</span> <span class="toc-text">2.7 Deep Transfer Learning&#x2F;Lifelong Machine Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-8-One-Shot-Deep-Learning"><span class="toc-number">2.8.</span> <span class="toc-text">2.8 One-Shot Deep Learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Applications"><span class="toc-number">3.</span> <span class="toc-text">3 Applications</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-NLP"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 NLP</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-Object-Detection"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 Object Detection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-Visual-Tracking"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 Visual Tracking</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-Image-Caption-Generator"><span class="toc-number">3.4.</span> <span class="toc-text">3.4 Image Caption Generator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-Neural-Machine-Translation"><span class="toc-number">3.5.</span> <span class="toc-text">3.5 Neural Machine Translation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-Robotics"><span class="toc-number">3.6.</span> <span class="toc-text">3.6 Robotics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-7-Art"><span class="toc-number">3.7.</span> <span class="toc-text">3.7 Art</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-8-Semantic-Segmentation"><span class="toc-number">3.8.</span> <span class="toc-text">3.8 Semantic Segmentation</span></a></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&text=The Deep Learning Papers reading roadmap"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&is_video=false&description=The Deep Learning Papers reading roadmap"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=The Deep Learning Papers reading roadmap&body=Check out this article: http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&title=The Deep Learning Papers reading roadmap"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&name=The Deep Learning Papers reading roadmap&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%B7%AF%E7%BA%BF%E5%9B%BE/&t=The Deep Learning Papers reading roadmap"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2023
    Fred Fang
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
